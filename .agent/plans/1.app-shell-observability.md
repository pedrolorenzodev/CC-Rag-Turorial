# Module 1: App Shell + Observability

**Complexity:** ⚠️ Medium - Multiple integrations but well-defined scope

## Overview

Build the foundational RAG application with:

- React + Vite + Tailwind + shadcn/ui frontend
- Python + FastAPI backend with venv
- Supabase Auth + Postgres with RLS
- OpenAI Responses API (managed threads + file_search)
- LangSmith observability
- SSE streaming for chat responses

---

## Phase 1: Project Scaffolding (Parallelizable)

### Task 1.1: Frontend Setup

Create React + Vite + TypeScript project at `/frontend`:

- Install Tailwind CSS + shadcn/ui
- Install `@supabase/supabase-js`
- Create folder structure: `components/`, `hooks/`, `lib/`, `pages/`, `types/`, `contexts/`
- Create `.env.example`

**Validation:** `npm run dev` starts, Tailwind works, shadcn component renders

### Task 1.2: Backend Setup

Create Python project at `/backend`:

- Create venv: `python -m venv venv`
- Install: `fastapi`, `uvicorn`, `openai`, `supabase`, `langsmith`, `sse-starlette`, `pydantic`, `python-dotenv`
- Create folder structure: `app/routers/`, `app/services/`, `app/models/`, `app/middleware/`
- Create `.env.example`

**Validation:** `uvicorn app.main:app --reload` starts, `/docs` shows Swagger UI

---

## Phase 2: Supabase + Database

### Task 2.1: Database Schema with RLS

Create `/supabase/migrations/`:

**threads table:**

```sql
CREATE TABLE threads (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  title TEXT,
  openai_thread_id TEXT,
  vector_store_id TEXT,
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);

ALTER TABLE threads ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can CRUD own threads" ON threads
  FOR ALL USING (auth.uid() = user_id);
```

**messages table:**

```sql
CREATE TABLE messages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  thread_id UUID NOT NULL REFERENCES threads(id) ON DELETE CASCADE,
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  role TEXT NOT NULL CHECK (role IN ('user', 'assistant')),
  content TEXT NOT NULL,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT now()
);

ALTER TABLE messages ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own messages" ON messages
  FOR SELECT USING (EXISTS (
    SELECT 1 FROM threads WHERE threads.id = messages.thread_id AND threads.user_id = auth.uid()
  ));

CREATE POLICY "Users can insert own messages" ON messages
  FOR INSERT WITH CHECK (auth.uid() = user_id);
```

**Validation:** Run migrations, test RLS blocks cross-user access

---

## Phase 3: Authentication

### Task 3.1: Backend Auth Middleware

Create `/backend/app/middleware/auth.py`:

- JWT verification via Supabase
- `get_current_user` dependency for protected routes
- Pass user context for RLS

**Validation:** Protected endpoint rejects invalid tokens, accepts valid ones

### Task 3.2: Frontend Auth

Create auth components:

- `/frontend/src/lib/supabase.ts` - Supabase client
- `/frontend/src/contexts/AuthContext.tsx` - Auth state
- `/frontend/src/components/auth/LoginForm.tsx`
- `/frontend/src/components/auth/SignupForm.tsx`
- `/frontend/src/components/auth/AuthGuard.tsx` - Protected route wrapper

**Validation:** Sign up, log in, session persists on refresh, sign out clears session

---

## Phase 4: Thread Management

### Task 4.1: Thread API

Create `/backend/app/routers/threads.py`:

- `GET /api/threads` - List user's threads
- `POST /api/threads` - Create thread
- `GET /api/threads/{id}` - Get thread
- `DELETE /api/threads/{id}` - Delete thread
- `GET /api/threads/{id}/messages` - Get messages

**Validation:** CRUD works, RLS enforced

### Task 4.2: Thread UI

Create components:

- `/frontend/src/components/chat/ThreadList.tsx`
- `/frontend/src/components/chat/ThreadItem.tsx`
- `/frontend/src/hooks/useThreads.ts`

**Validation:** Create, switch, delete threads; persists on refresh

---

## Phase 5: OpenAI + Observability

### Task 5.1: LangSmith Setup

Create `/backend/app/services/langsmith_service.py`:

```python
from langsmith.wrappers import wrap_openai
from langsmith import traceable
import openai

client = wrap_openai(openai.Client())
```

**Validation:** API call creates trace in LangSmith dashboard

### Task 5.2: OpenAI Responses API Service

Create `/backend/app/services/openai_service.py`:

- `create_response()` - Create response with optional `previous_response_id` and `vector_store_id`
- `create_vector_store()` - Create vector store for file_search
- Wrap with LangSmith `@traceable`
- Enable streaming with `stream=True, store=True`

**Validation:** Responses chain correctly with `previous_response_id`

### Task 5.3: SSE Streaming Endpoint

Create `/backend/app/routers/chat.py`:

- `POST /api/threads/{thread_id}/chat` returns `EventSourceResponse`
- Stream OpenAI response chunks as SSE events
- Save complete message to database
- Update thread's `openai_thread_id`

**Validation:** Messages stream in real-time, persist to database

---

## Phase 6: Chat UI

### Task 6.1: Message Components

- `/frontend/src/components/chat/MessageBubble.tsx` - User/assistant styling
- `/frontend/src/components/chat/MessageList.tsx`
- `/frontend/src/components/chat/TypingIndicator.tsx`

### Task 6.2: Chat Input

- `/frontend/src/components/chat/ChatInput.tsx` - Enter to send, disabled during stream

### Task 6.3: SSE Integration

- `/frontend/src/hooks/useChat.ts` - Fetch with ReadableStream for SSE POST
- `/frontend/src/components/chat/ChatContainer.tsx`

**Validation:** Send message, watch stream, messages persist

---

## Phase 7: Final Integration

### Task 7.1: Main Layout

- `/frontend/src/layouts/MainLayout.tsx` - Sidebar + chat area
- `/frontend/src/pages/ChatPage.tsx`
- Update `/frontend/src/App.tsx`

### Task 7.2: End-to-End Testing

- [ ] Sign up new user
- [ ] Log in
- [ ] Create thread
- [ ] Send message, receive streaming response
- [ ] Verify conversation context maintained
- [ ] Switch between threads
- [ ] Sign out
- [ ] Verify LangSmith traces
- [ ] Verify RLS blocks cross-user access

---

## Environment Variables

### Frontend `.env`

```
VITE_SUPABASE_URL=
VITE_SUPABASE_ANON_KEY=
VITE_API_URL=http://localhost:8000
```

### Backend `.env`

```
SUPABASE_URL=
SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=
OPENAI_API_KEY=
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=rag-masterclass
```

---

## Critical Files

| File                                      | Purpose                          |
| ----------------------------------------- | -------------------------------- |
| `/backend/app/services/openai_service.py` | OpenAI Responses API + LangSmith |
| `/backend/app/routers/chat.py`            | SSE streaming endpoint           |
| `/backend/app/middleware/auth.py`         | JWT verification for RLS         |
| `/frontend/src/hooks/useChat.ts`          | SSE consumption + state          |
| `/supabase/migrations/*.sql`              | Schema + RLS policies            |

---

## Risks & Mitigations

1. **SSE with Auth Headers**: EventSource doesn't support headers → Use fetch with ReadableStream
2. **RLS with Backend**: Backend needs user JWT for Supabase → Create authenticated client per request
3. **LangSmith + Async Streaming**: May need special handling → Test early in Task 5.1
